{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyP9M/PsnGeEkiHYVnDXwlXD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["### Preparation to build a code for ANN training\n","\n","*   Access to your google drive\n","*   Import tensorflow framework to run deep learning model\n","*   Allocate GPU"],"metadata":{"id":"TAkXtYepQeFU"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"JBJEJ9lQyo3S"},"outputs":[],"source":["# Access to Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["# Import 'Tensorflow' package\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","# Check the version of tensorflow\n","print(tf.__version__)"],"metadata":{"id":"ibA8XFL0O-C4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check if a GPU(in Google server) is allocated\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","    raise SystemError('GPU device not found')\n","\n","print('Found GPU at: {}'.format(device_name))"],"metadata":{"id":"FFFVOt_5KkbS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Step 5-1: ANN\n","We've extracted the features of the classified data in ML8_1.\n","\n","We'll train ANN model using those feature data.\n","\n","Plase refer ML 7_1 for ANN grid search."],"metadata":{"id":"gKTBNRYmyu1B"}},{"cell_type":"markdown","source":["Prepare the selected features data"],"metadata":{"id":"vanOjYVb0i6-"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.preprocessing import StandardScaler\n","\n","# Load selected feature data and P-values at Step 4-1 in ML8_1\n","feature_path = \"YOUR_PATH/FeatureSelected.csv\"\n","p_rank_path = 'YOUR_PATH/P_value_Rank.csv'\n","\n","FeatureSelected = pd.read_csv(feature_path, header=None)\n","P_value_Rank = pd.read_csv(p_rank_path , header=None)\n","\n","# Standardize the selected features\n","FeatureSelected_std = StandardScaler().fit_transform(pd.DataFrame(FeatureSelected).T)\n","FeatureSelected_std.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KDimHt8gytA4","executionInfo":{"status":"ok","timestamp":1711463443670,"user_tz":240,"elapsed":3129,"user":{"displayName":"Jurim Jeon","userId":"10955320382451118190"}},"outputId":"24b66871-259f-4fbb-ebc9-e75c7c789ba7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(623, 30)"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["# Split feature data into 6 classes back\n","num_class=6\n","num_data=[96, 161, 144, 41, 34, 147] # 1 segment per 1 second with 0.8 second overlap\n","\n","\n","# Index feature data\n","\n"],"metadata":{"id":"ZcBel_TE1CBW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Split dataset into training and test sets"],"metadata":{"id":"JrZdhuA_0qtc"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","# Define the test data ratio\n","test_ratio = 0.2\n","\n","# Split the datasets into training and test sets\n","\n","### You need to split all classified data into train and test sets.\n","### Examples below.\n","TRAIN_DATA_CLASS1, TEST_DATA_CLASS1 = train_test_split(DATA_CLASS1, test_size=test_ratio, random_state=777)\n","TRAIN_DATA_CLASS2, TEST_DATA_CLASS2 = train_test_split(DATA_CLASS2, test_size=test_ratio, random_state=777)\n","...\n","\n"],"metadata":{"id":"PmbjKOhEUlph"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### How to handle iterative codes\n","### This is how to make your code more organized; it's not an essential thing!\n","\n","### If you need to perform the same task repeatedly and you're doing it one by one,\n","### that would be like below.\n","TRAIN_DATA_CLASS1, TEST_DATA_CLASS1 = train_test_split(DATA_CLASS1, test_size=test_ratio, random_state=777)\n","TRAIN_DATA_CLASS2, TEST_DATA_CLASS2 = train_test_split(DATA_CLASS2, test_size=test_ratio, random_state=777)\n","TRAIN_DATA_CLASS3, TEST_DATA_CLASS3 = train_test_split(DATA_CLASS3, test_size=test_ratio, random_state=777)\n","TRAIN_DATA_CLASS4, TEST_DATA_CLASS4 = train_test_split(DATA_CLASS4, test_size=test_ratio, random_state=777)\n","TRAIN_DATA_CLASS5, TEST_DATA_CLASS5 = train_test_split(DATA_CLASS5, test_size=test_ratio, random_state=777)\n","TRAIN_DATA_CLASS6, TEST_DATA_CLASS6 = train_test_split(DATA_CLASS6, test_size=test_ratio, random_state=777)\n","\n","### You can make these repeated codes as a 'for' loop\n","for i in range(num_class): # i starts from '0' and ends with 'num_class-0'\n","  exec(f\"TRAIN_DATA_CLASS{i+1}, TEST_DATA_CLASS{i+1} = train_test_split(DATA_CLASS{i+1}, test_size=test_ratio, random_state=777)\")"],"metadata":{"id":"RRz90lwpUjl4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Make label (One-hot Encoding)\n","### You need to make label for training and test.\n","### For class 1, the label is like [1 0 0 0 0 0],\n","### for class 2, the label is like [0 1 0 0 0 0], and so on ...\n","### Examples below (You can use a loop of course!)\n","TRAIN_LABEL_CLASS1=np.zeros((TRAIN_DATA_CLASS1.shape[0],num_class))\n","TRAIN_LABEL_CLASS1[:,0]=1\n","TEST_LABEL_CLASS1=np.zeros((TEST_DATA_CLASS1.shape[0],num_class))\n","TEST_LABEL_CLASS1[:,0]=1\n","...\n","\n","\n","\n","# Combine the classified data/labels\n","### Now, you need to combine all classified train and test data into train and test dataset\n","### and train and test label into a train label set and test label set.\n","TrainData = np.concatenate([TRAIN_DATA_CLASS1, TRAIN_DATA_CLASS2, ..., TRAIN_DATA_CLASS6], axis=0)\n","TestData = np.concatenate([TEST_DATA_CLASS1, TEST_DATA_CLASS2, ..., TEST_DATA_CLASS6], axis=0)\n","TrainLabel = np.concatenate([TRAIN_LABEL_CLASS1, TRAIN_LABEL_CLASS2, ..., TRAIN_LABEL_CLASS6], axis=0)\n","TestLabel = np.concatenate([TEST_LABEL_CLASS1, TEST_LABEL_CLASS2, ..., TEST_LABEL_CLASS6], axis=0)\n","\n","print(\"- total train data\", TrainData.shape,  \", test data\", TestData.shape)\n","print(\"- total train label\", TrainLabel.shape, \", test label\",TestLabel.shape)"],"metadata":{"id":"nTQme1fCdWUZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Prepare lists of hyperparameters for grid search"],"metadata":{"id":"kUAIYKYh7P_W"}},{"cell_type":"code","source":["# Set hyperparameters for grid search\n","activation_function = ['tanh', 'relu'] # activation function\n","hidden_layer = [2, 3] # number of hiddent layers\n","learning_rate = [0.001, 0.01] # learning rate\n","\n","# Set hyperparameters for each training\n","num_neuron = 16\n","epoch = 300\n","\n","# Calculate the number of cases\n","num_case = len(activation_function) * len(hidden_layer) * len(learning_rate)\n","print(\"We're gonna run\", num_case, \"models\")"],"metadata":{"id":"FDQBOJK17O-z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define a function to create ANN models by inputting the hyperparameters for grid search\n","### You can refer ML7_1\n","### Please keep in mind that the output node units should be same with the number of classes\n","def ANN_model(input_data, num_neuron, temp_actfn, temp_layer, temp_lr):\n","\n","\n","\n","\n","\n","  return model"],"metadata":{"id":"yLZgC5yV1FTK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create an empty dataframe to store the accuracy results\n","Accuracy_df = pd.DataFrame(np.zeros(shape=(num_case, 4)), columns=['Activation Function', 'Num of hidden layer', 'Learning rate', 'Accuracy'])"],"metadata":{"id":"KXHMkdQ01kZa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Train the ANN models with different combinations of hyperparameters and save them"],"metadata":{"id":"Aqyq7QH6160M"}},{"cell_type":"code","source":["# Initialize a count value to store the performance of each model\n","cnt = 0\n","\n","# Iterate through all possible combinations of activation functions, hidden layers, and learning rates\n","for act_func in activation_function: # Select each activation function in the list\n","    for layer in hidden_layer: # Select each hidden layer configuration in the list\n","        for lr in learning_rate: # Select each learning rate value in the list\n","\n","            # Create, train, and validate a temporary ANN model with the current combination of hyperparameters\n","            temp_ann_model = ...\n","\n","\n","            # Save the temporary model to a file with a corresponding name\n","            temp_ann_model_name = f'ANN_{act_func}_L{layer}_LR{lr:.4f}.h5'\n","            temp_ann_model.save('YOUR_PATH/GridSearch_ANN/' + temp_ann_model_name)\n","\n","            # Store the performance (accuracy) of the temporary model in the dataframe\n","            Accuracy_df.iloc[cnt, :] = [act_func, layer, lr, Accuracy]\n","            cnt += 1\n","\n","# Display the resulting dataframe with model performances\n","Accuracy_df"],"metadata":{"id":"bD1uVALc1kfo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Confirm the grid search results"],"metadata":{"id":"uGO22eGCatZX"}},{"cell_type":"code","source":["# Calculate mean and standard deviation accuracy for each activation function\n","mean_accuracy_actfn = Accuracy_df.groupby(['Activation Function'])['Accuracy'].agg(['mean', 'std']).reset_index()\n","\n","# Calculate mean and standard deviation of accuracy for each hidden layer\n","mean_accuracy_layer = Accuracy_df.groupby(['Num of hidden layer'])['Accuracy'].agg(['mean', 'std']).reset_index()\n","\n","# Calculate mean and standard deviation of accuracy for each learning rate\n","mean_accuracy_lr = Accuracy_df.groupby(['Learning rate'])['Accuracy'].agg(['mean', 'std']).reset_index()\n","\n","print(\"Mean accuarcy\\n\", mean_accuracy_actfn,\"\\n\\n\", mean_accuracy_layer, \"\\n\\n\",mean_accuracy_lr)"],"metadata":{"id":"m902xnjWNrpZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Visualize the performance comparison for the selected hyperparameter"],"metadata":{"id":"PqlOHaqCOIIj"}},{"cell_type":"code","source":["# Set an index to select a hyperparmeter\n","# 0: activation function // 1: number of hidden layers // 2: learning rate\n","idx = 1\n","\n","# Automatically define variables based on the selected index\n","hyper_param = ['actfn', 'layer', 'lr']\n","hyper_param_name = ['Activation Function', 'Num of hidden layer', 'Learning Rate']\n","selected = hyper_param[idx]\n","selected_name = hyper_param_name[idx]\n","exec('Result = mean_accuracy_' + hyper_param[idx])\n","\n","xLabel = Result.iloc[:, 0]\n","x_pos = np.arange(Result.shape[0])\n","y_val = Result['mean']\n","y_err = Result['std']\n","\n","# Draw a bar chart to compare the model performance (diagnostic accuracy) for each hyperparameter\n","import matplotlib.pyplot as plt\n","fig, ax = plt.subplots(figsize=(5, 4))\n","\n","# Create a bar plot with error bars\n","ax.bar(x_pos, y_val, yerr=y_err, align='center', alpha=0.5, ecolor='black', capsize=10,\n","       color=['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple'])\n","ax.set_ylabel('Accuracy (mean)', fontsize=12)\n","ax.set_title(f\"Performance comparsion by '{selected_name}'\\n\", fontsize=14)\n","ax.set_xticks(x_pos)\n","ax.set_xticklabels(xLabel, fontsize=12)\n","ax.yaxis.grid()\n","ax.set_ylim([0.6, 1.0])\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"Hz7zKJaDNrsF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Select the best model among 8 cases"],"metadata":{"id":"bR-0OX86MzEG"}},{"cell_type":"code","source":["# Sort the Accuracy_df by 'Accuracy' column in descending order\n","Accuracy_df_sorted = Accuracy_df.sort_values(by='Accuracy', ascending=False).reset_index(drop=True)\n","\n","# Retrieve activation function, hidden layers, and learning rate values from the first row of 'Accuracy_df_sorted'\n","best_actfn = Accuracy_df_sorted.iloc[0, 0]\n","best_layer = int(Accuracy_df_sorted.iloc[0, 1])\n","best_lr = Accuracy_df_sorted.iloc[0, 2]\n","best_accuracy = Accuracy_df_sorted.iloc[0, 3]\n","\n","# Output the best case\n","print(\"[Best case]\\nActivation Function: \" + best_actfn +\n","      \"\\nHidden Layers: %d\\nLearning Rate: %.4f\\n\\nAccuracy: %.2f\" % (best_layer, best_lr, best_accuracy))"],"metadata":{"id":"CkuLwEgmNTm4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the best ANN model using the retrieved hyperparameters\n","best_ann_model_name = f'ANN_{best_actfn}_L{best_layer}_LR{best_lr:.4f}.h5'\n","best_ann_model = keras.models.load_model('YOUR_PATH/GridSearch_ANN/' + best_ann_model_name)"],"metadata":{"id":"7s1qZKcbMyeS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Print layers in the model\n","best_ann_model.summary()"],"metadata":{"id":"GoRQK7zIMr1F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot model architecture\n","keras.utils.plot_model(best_ann_model, dpi=80, show_shapes=True) # dpi: image resolution in dots per inch"],"metadata":{"id":"F170D4ucNyxA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["[Confusion matrix] for the best ANN model"],"metadata":{"id":"_5XlgXTsOdKL"}},{"cell_type":"code","source":["import seaborn as sns\n","from sklearn.metrics import confusion_matrix\n","\n","# Predict the output (Robotic spot-welding condition) for the test data\n","Predicted = best_ann_model.predict(TestData)\n","\n","# Convert TestLabel and Predicted into vectors to calculate the confusion matrix and evaluation metrics\n","TestLabel_rev = np.argmax(TestLabel, axis=1)\n","Predicted_rev = np.argmax(Predicted, axis=1)\n","\n","# Calculate the confusion matrix\n","cm = confusion_matrix(TestLabel_rev, Predicted_rev)"],"metadata":{"id":"7lU86fYdPC0Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot the confusion matrix\n","plt.figure(figsize=(6, 6))\n","sns.heatmap(cm, annot=True, fmt='d', cmap=plt.cm.Blues, cbar=False, square=True)\n","plt.xlabel(\"Predicted label\")\n","plt.ylabel(\"True label\")\n","plt.title(\"Confusion Matrix of the Best ANN Model\")\n","plt.show()"],"metadata":{"id":"owiiHAqTNrut"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Normalize confusion matrix to show percentages\n","### You need to normalize to calculate the percentages of each result\n","### For class 1, (19)/(19 + 1),\n","### for class 2, (30)/(30 + 3), ...\n","\n","cm_percent =\n","\n","# Plot the percentage confusion matrix\n","plt.figure(figsize=(6, 6))\n","sns.heatmap(cm_percent, annot=True, fmt='.2f', cmap=plt.cm.Blues, cbar=False, square=True)\n","plt.xlabel(\"Predicted label\")\n","plt.ylabel(\"True label\")\n","plt.title(\"Confusion Matrix of the Best ANN Model (Percentage)\")\n","plt.show()"],"metadata":{"id":"sqFqsmLdO4PT"},"execution_count":null,"outputs":[]}]}